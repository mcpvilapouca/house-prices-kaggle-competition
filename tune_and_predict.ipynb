{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook tunes two of the most promising models, and creates the predictions of the test set for the best tunned model\n",
    "\n",
    "- A validation set (10%) is created to evaluate the final models\n",
    "- RandomizedSearchCV is performed with the remaining training set (90%). A pipeline is introduced so that the RandomizedSearchCV is performed with KFold and provides robuster results\n",
    "- XGboost and the KernelRidge were chosen to be tuned\n",
    "- The best estimators were then retrained for 90% of the training set and evaluated with the validation set. \n",
    "- XGBoost showed the best result and was chosen to make the predictions of the test set and create the submission file\n",
    "\n",
    "* The results are saved to a log file: tune_and_predict.log\n",
    "\n",
    "Note: We tried GridSearchCV with worst results. However, this could be used for finer tunning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.model_selection import KFold\n",
    "import create_models\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import RepeatedKFold\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "import numpy as np\n",
    "import pickle\n",
    "from datetime import datetime\n",
    "from sklearn.metrics import make_scorer\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "\n",
    "logging.basicConfig(level=logging.DEBUG, filename=\"run_gridsearch.log\", filemode=\"a+\",\n",
    "                        format=\"%(asctime)-15s %(levelname)-8s %(message)s\",force=True)\n",
    "\n",
    "\n",
    "\n",
    "# Define a function to calculate RMSE\n",
    "def rmse(y_true, y_pred):\n",
    "    return np.sqrt(np.mean((y_true-y_pred)**2))\n",
    "\n",
    "# Define a function to calculate negative RMSE (as a score)\n",
    "def nrmse(y_true, y_pred):\n",
    "    return -1.0*rmse(y_true, y_pred)\n",
    "\n",
    "neg_rmse = make_scorer(nrmse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#use selected features ('yes) vs all features 'no'\n",
    "sfeat='yes'\n",
    "\n",
    "if sfeat=='no':\n",
    "   read_features='None'\n",
    "else:\n",
    "   read_features='features_2906'\n",
    "\n",
    "#test and train files\n",
    "train_file='train_data_2906_ro'\n",
    "test_file='test_data_2906_ro'\n",
    "\n",
    "logging.info(\"\\n---------------- NEW RUN ----------------\\n\"+\n",
    "'* selected features: '+sfeat+'\\n'+\n",
    "'*features file '+read_features+'\\n'+\n",
    "'*outliers: removed\\n'\n",
    "'*normalized data: yes'+'\\n\\n')\n",
    "\n",
    "#read data\n",
    "\n",
    "df=pd.read_pickle(train_file+\".pkl\")\n",
    "df_test=pd.read_pickle(test_file+\".pkl\")\n",
    "X_test=df_test\n",
    "\n",
    "y=np.array(df.SalePrice)\n",
    "\n",
    "y=np.log(y)\n",
    "\n",
    "if sfeat=='yes':\n",
    "    with open(read_features, \"rb\") as fp:   # Unpickling\n",
    "        features = pickle.load(fp)\n",
    "    df=df[features]\n",
    "    X_test=X_test[features]\n",
    "else:\n",
    "    df=df.drop('SalePrice', axis=1)\n",
    "    X_test=df_test.drop('Id')\n",
    "#--------------------------------------------\n",
    "X=np.array(df)\n",
    "X_test=np.array(X_test)\n",
    "\n",
    "xgboost=create_models.xgboost(n_jobs=4)\n",
    "ridge=create_models.ridge()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train,X_val,y_train,y_val=train_test_split(X,y,test_size=0.1,random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'model__subsample': 0.6, 'model__scale_pos_weight': 0.2, 'model__reg_lambda': 1.0, 'model__reg_alpha': 1.25, 'model__n_estimators': 470, 'model__min_child_weight': 4, 'model__max_depth': 2, 'model__learning_rate': 0.13, 'model__gamma': 0.0}\n",
      "-0.1135583875606003\n"
     ]
    }
   ],
   "source": [
    "logging.info('___________\\nRandomizeSearchCV: XG Boost\\n____________\\n')\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# define the pipeline\n",
    "steps = list()\n",
    "\n",
    "steps.append(('scaler', MinMaxScaler()))\n",
    "steps.append(('model', xgboost))\n",
    "pipeline = Pipeline(steps=steps)\n",
    "    \n",
    "# define the evaluation procedure\n",
    "cv = KFold(n_splits=5, random_state=1,shuffle=True)\n",
    "\n",
    "\n",
    "param_grid_xgb = {\n",
    "    \"model__n_estimators\":list(range(50, 500, 10)),\n",
    "    'model__max_depth': list(range(2, 20)),\n",
    "    \"model__learning_rate\": list(np.arange(0.05, 0.55,0.01)),\n",
    "    \"model__gamma\": list(np.arange(0, 1.5, 0.1)),\n",
    "    \"model__reg_alpha\": list(np.arange(0, 1.5, 0.05)),\n",
    "    \"model__reg_lambda\": list(np.arange(0, 5, 0.5)),\n",
    "    \"model__scale_pos_weight\": list(np.arange(0.1, 1.5, 0.1)),\n",
    "    \"model__subsample\": list(np.arange(0.1, 2.0, 0.1)),\n",
    "    \"model__min_child_weight\":list(np.arange(1, 7,1))\n",
    "}\n",
    "    \n",
    "# tune model\n",
    "rs_xgb=RandomizedSearchCV(pipeline, param_distributions=param_grid_xgb, n_iter = 2000,scoring =neg_rmse, cv=cv, n_jobs=10)\n",
    "\n",
    "rs_xgb.fit(X_train,y_train)\n",
    "\n",
    "# print best parameter after tuning \n",
    "print(rs_xgb.best_params_)\n",
    "print(rs_xgb.best_score_)\n",
    "logging.info('\\nXGBoost Best parameters:\\n'+str(rs_xgb.best_params_))\n",
    "logging.info('\\nXGBoost Best score:\\n'+str(rs_xgb.best_score_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'model__alpha': 0.05014627465656736, 'model__coef0': 2.696019523063539, 'model__degree': 2, 'model__kernel': 'polynomial'}\n",
      "-0.11263980386958301\n"
     ]
    }
   ],
   "source": [
    "logging.info('___________\\nRandomizedSearchCV: Ridge\\n____________\\n')\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "from scipy.stats import uniform\n",
    "ridge=create_models.ridge()\n",
    "\n",
    "# define the pipeline\n",
    "steps = list()\n",
    "\n",
    "steps.append(('scaler', MinMaxScaler()))\n",
    "steps.append(('model', ridge))\n",
    "pipeline = Pipeline(steps=steps)\n",
    "    \n",
    "# define the evaluation procedure\n",
    "cv = KFold(n_splits=5, random_state=1,shuffle=True)\n",
    "\n",
    "\n",
    "param_grid_ridge = {\n",
    "    'model__alpha': uniform(0.05, 1.0), \n",
    "    'model__kernel': ['polynomial'], \n",
    "    'model__degree': [2], \n",
    "    'model__coef0':uniform(0.5, 3.5)}\n",
    "    \n",
    "# tune model\n",
    "rs_ridge=RandomizedSearchCV(pipeline, param_distributions=param_grid_ridge,n_iter = 2000, scoring =neg_rmse, cv=cv, n_jobs=10)\n",
    "\n",
    "rs_ridge.fit(X_train,y_train)\n",
    "\n",
    "# print best parameter after tuning \n",
    "print(rs_ridge.best_params_)\n",
    "print(rs_ridge.best_score_)\n",
    "logging.info('\\nRidge Best parameters:\\n'+str(rs_ridge.best_params_))\n",
    "logging.info('\\nRidge Best score:\\n'+str(rs_ridge.best_score_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "xgboost: 0.1313217520354582\n",
      "ridge: 0.13333515854437233\n"
     ]
    }
   ],
   "source": [
    "best_models=[rs_xgb.best_estimator_, rs_ridge.best_estimator_]\n",
    "labels=['xgboost', 'ridge']\n",
    "\n",
    "\n",
    "for i,model in enumerate(best_models):\n",
    "    scaler=MinMaxScaler()\n",
    "    X_train_scaled=scaler.fit_transform(X_train)\n",
    "    X_val_scaled=scaler.transform(X_val)\n",
    "\n",
    "    model.fit(X_train_scaled,y_train)\n",
    "\n",
    "    y_pred=model.predict(X_val_scaled)\n",
    "\n",
    "    rmse_score=rmse(y_val,y_pred)\n",
    "\n",
    "    print(labels[i]+': '+str(rmse_score))\n",
    "    logging.info('\\n'+labels[i]+': '+str(rmse_score)+'\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "model=rs_xgb.best_estimator_\n",
    "\n",
    "#Predict Test Set\n",
    "scaler=MinMaxScaler()\n",
    "X_scaled=scaler.fit_transform(X)\n",
    "\n",
    "X_test_scaled=scaler.transform(X_test)\n",
    "\n",
    "model.fit(X_scaled,y)\n",
    "\n",
    "# make predictions for test data\n",
    "y_pred = model.predict(X_test_scaled)\n",
    "\n",
    "#return predictions from log\n",
    "y_pred=np.exp(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#save predictions to .csv file\n",
    "dateTimeObj=datetime.now()\n",
    "submission=pd.DataFrame(columns=('Id','SalePrice'))\n",
    "submission['Id']=df_test['Id']\n",
    "submission['Id'] = submission['Id'].astype(int)\n",
    "submission['SalePrice']=y_pred\n",
    "submission.to_csv('submission'+str(dateTimeObj.year)+str(dateTimeObj.month)+\n",
    "str(dateTimeObj.day)+'_'+str(dateTimeObj.hour)+str(dateTimeObj.minute)+str(dateTimeObj.second)+'.csv',index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
